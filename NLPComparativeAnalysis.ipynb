{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.0\n",
        "!pip install gensim --upgrade --force-reinstall"
      ],
      "metadata": {
        "id": "YueakxRw8WSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0811665e-97f1-4c13-bf94-1ac3b4526fbb"
      },
      "id": "YueakxRw8WSv",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.0\n",
            "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "Successfully installed numpy-1.26.0\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.0\n",
            "    Uninstalling numpy-1.26.0:\n",
            "      Successfully uninstalled numpy-1.26.0\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufSwdxxyex2w",
        "outputId": "68a659c7-2045-4a8a-89c7-8209fb22ade1"
      },
      "id": "ufSwdxxyex2w",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numba -y\n",
        "!pip install numba==0.60.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtNn_YLEHxcc",
        "outputId": "8d730027-0c33-48a1-c124-024a000d4ec2"
      },
      "id": "YtNn_YLEHxcc",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numba 0.60.0\n",
            "Uninstalling numba-0.60.0:\n",
            "  Successfully uninstalled numba-0.60.0\n",
            "Collecting numba==0.60.0\n",
            "  Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba==0.60.0) (0.43.0)\n",
            "Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.11/dist-packages (from numba==0.60.0) (1.26.4)\n",
            "Downloading numba-0.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numba\n",
            "Successfully installed numba-0.60.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.18.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz2fz3NYH4o0",
        "outputId": "1288bf55-b70d-47c0-82af-28ec38b4659b"
      },
      "id": "Wz2fz3NYH4o0",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.18.0 in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (4.13.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.18.0) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.18.0) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow==2.18.0) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.18.0) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow==2.18.0) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow==2.18.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.18.0) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.kill(os.getpid(), 9)  # Restart the runtime to apply changes"
      ],
      "metadata": {
        "id": "0Bc_i4B8ISEA"
      },
      "id": "0Bc_i4B8ISEA",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import gensim\n",
        "import tensorflow\n",
        "import numba\n",
        "\n",
        "print(f\"NumPy version: {numpy.__version__}\")\n",
        "print(f\"Gensim version: {gensim.__version__}\")\n",
        "print(f\"TensorFlow version: {tensorflow.__version__}\")\n",
        "print(f\"Numba version: {numba.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiL3W5E7IjfA",
        "outputId": "c3f22cdd-217e-4a38-ef6f-b78e6fda1b93"
      },
      "id": "CiL3W5E7IjfA",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version: 1.26.4\n",
            "Gensim version: 4.3.3\n",
            "TensorFlow version: 2.18.0\n",
            "Numba version: 0.60.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()  # Releases unoccupied cached memory\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)  # To check memory status"
      ],
      "metadata": {
        "id": "yob1XPQs5Bl2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "7a92f888-01d5-4f2d-c1db-99cd0919de71"
      },
      "id": "yob1XPQs5Bl2",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation & Embeddings"
      ],
      "metadata": {
        "id": "IZKGfZeP-HJB"
      },
      "id": "IZKGfZeP-HJB"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "83cf7311-4439-486e-9c30-e578585c4c14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83cf7311-4439-486e-9c30-e578585c4c14",
        "outputId": "ce3054e9-a075-42a3-eac7-91b683fce175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "All packages imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Force GPU usage\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "print(\"All packages imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load & Preprocess Dataset"
      ],
      "metadata": {
        "id": "AikRGSMl-WtC"
      },
      "id": "AikRGSMl-WtC"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7f7b8079-c866-48bc-b0d6-e3c687d85ed7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f7b8079-c866-48bc-b0d6-e3c687d85ed7",
        "outputId": "d43f5532-7ac1-4508-aa6e-ba2964b492f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [polarity, text]\n",
            "Index: []\n",
            "Total samples: 1048572\n",
            "Training samples: 849342\n",
            "Validation samples: 94372\n",
            "Testing samples: 104858\n"
          ]
        }
      ],
      "source": [
        "def load_and_preprocess_data(file_path):\n",
        "    columns = ['polarity', 'id', 'date', 'query', 'user', 'text']\n",
        "\n",
        "        # Adding 'error_bad_lines' to skip problematic rows and 'on_bad_lines' for pandas >=1.3.0\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, encoding='latin-1', names=columns, on_bad_lines='skip', skiprows=1,low_memory=False)\n",
        "    except:\n",
        "        df = pd.read_csv(file_path, encoding='latin-1', names=columns, error_bad_lines=False,skiprows=1,)  # For older versions of pandas\n",
        "\n",
        "    df = df[['polarity', 'text']]\n",
        "\n",
        "    label_mapping = {0: 0, 2: 1, 4: 2}\n",
        "    df['polarity'] = df['polarity'].map(label_mapping)\n",
        "\n",
        "    def clean_text(text):\n",
        "        text = str(text).lower()\n",
        "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "        text = re.sub(r'[^a-z0-9 ]', '', text)\n",
        "        return text\n",
        "\n",
        "    df['text'] = df['text'].apply(clean_text)\n",
        "    return df\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Analytics Vidhya/Generative AI/NLP using PyTorch/archive/training.1600000.processed.noemoticon.csv'\n",
        "data = load_and_preprocess_data(file_path)\n",
        "\n",
        "invalid_data = data[(data['polarity'] < 0) | (data['polarity'] > 2)]\n",
        "print(invalid_data)\n",
        "\n",
        "X = data['text'].values\n",
        "y = data['polarity'].values\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Displaying dataset information\n",
        "print(f\"Total samples: {len(data)}\")\n",
        "print(f\"Training samples: {len(train_texts)}\")\n",
        "print(f\"Validation samples: {len(val_texts)}\")\n",
        "print(f\"Testing samples: {len(test_texts)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "17b63701-d2bb-4627-85e6-5c05bea52e4c",
      "metadata": {
        "id": "17b63701-d2bb-4627-85e6-5c05bea52e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "0d00b677790242febcfa5cb77b60575c",
            "fbefbc7e606246e085571dfb73e52d6d",
            "0d6a9ad89d9c4bb78edefefa029a408a",
            "899993c77d1c438ca3bc0e22b3598360",
            "787901ddb141464583c3b00fe6c910f3",
            "0c2870f6140344f88ddb2d68ca0f0f69",
            "f7eaf597631d492b8b22c1dfb15252ae",
            "13ce597263ee44a4a899d3a38e8a2bbe",
            "0bbe923adb3144afabad4432dba3ec57",
            "b19e483e83204dbaaa74eec31b70d375",
            "1ca21310b0004aeabd5fcef9256aadfb",
            "f71fbb0ca9374e26ae5d2310e4dffb6c",
            "16a4fd9494834a5e8297be395c23f71a",
            "c8db4d7cb53e4f96bd6e451e625284e8",
            "10058237e8df426184e781d11e641f36",
            "c342d85d635f4f4db3c69e03c5796210",
            "7f163f0fe1da40969b8c51ed09600870",
            "235869d2d02f456c870a570fa9f7e99a",
            "c6d5ce885bcb4f5bad31b3bc869399a2",
            "152182fe82674bce98dba8bed33fa622",
            "dc9a69b9c3e340f795083082fe7f2c4f",
            "081778fcd92a4fe79abefd2502f789f9",
            "a7aa929055164a33a8ab30a680864f64",
            "ca3a67d2367d462d8123cdefab4209cd",
            "a7d706469fec4b9d9b504142505a81cb",
            "4d7debefa240474f9c62abc302bad769",
            "44491ee6eb574239b05ab573d0e905bd",
            "22e15a52ecd94eafb306c465a4021ba8",
            "d30f4e92a378493f857608a076a75c5c",
            "b898e2e390a34573a95e4daa3e4a5968",
            "fe837e1e890d45388dd70d855f54bb31",
            "18b2340921d742f6bf35327f548d6abf",
            "260ecb8e1d414067a269d1e675861269",
            "f5bee94ee6c4419381f1cb80d2b8e7e1",
            "2130536c322747da9fde1787a88de294",
            "6fbfe8d849b242118119b58c567c3030",
            "d34e7430bcbe4dde9067481c168dffe6",
            "e6224bb4bcb24ee08401b1b8a8ec0940",
            "8ad4769a8bdf47b7881da7a63e4eea90",
            "4989536a16524048b032e80fa743dfd7",
            "a9d23fbefb694de4b0c512cc132b1366",
            "cb97ba8c23654957b6dfa6a62a3c8482",
            "fa03e3f7fd9a4ea0917c40e72616de4e",
            "10d45d9f21cc4d7f878cc5cc1ae96f2b"
          ]
        },
        "outputId": "f558b249-6b31-4e80-b19c-5d328ab6db5c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d00b677790242febcfa5cb77b60575c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f71fbb0ca9374e26ae5d2310e4dffb6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7aa929055164a33a8ab30a680864f64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5bee94ee6c4419381f1cb80d2b8e7e1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import gensim.downloader as api\n",
        "\n",
        "# Initialize BERT tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def encode_texts(texts, max_length=128):\n",
        "    input_ids, attention_masks = [], []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded = bert_tokenizer.encode_plus(text, add_special_tokens=True, max_length=max_length, padding='max_length',\n",
        "                                             return_attention_mask=True, truncation=True)\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "    return torch.tensor(input_ids).to(device), torch.tensor(attention_masks).to(device)\n",
        "\n",
        "# Encode BERT Inputs\n",
        "train_inputs, train_masks = encode_texts(train_texts)\n",
        "val_inputs, val_masks = encode_texts(val_texts)\n",
        "test_inputs, test_masks = encode_texts(test_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "25275c9e-1e9f-4d1a-b352-bedea2114e3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25275c9e-1e9f-4d1a-b352-bedea2114e3c",
        "outputId": "7a5b3343-58eb-48f7-9d16-37243f5b384e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved embedding_batches/train_batch_0.pt successfully.\n",
            "Saved embedding_batches/train_batch_1.pt successfully.\n",
            "Saved embedding_batches/train_batch_2.pt successfully.\n",
            "Saved embedding_batches/train_batch_3.pt successfully.\n",
            "Saved embedding_batches/train_batch_4.pt successfully.\n",
            "Saved embedding_batches/train_batch_5.pt successfully.\n",
            "Saved embedding_batches/train_batch_6.pt successfully.\n",
            "Saved embedding_batches/train_batch_7.pt successfully.\n",
            "Saved embedding_batches/train_batch_8.pt successfully.\n",
            "Saved embedding_batches/train_batch_9.pt successfully.\n",
            "Saved embedding_batches/train_batch_10.pt successfully.\n",
            "Saved embedding_batches/train_batch_11.pt successfully.\n",
            "Saved embedding_batches/train_batch_12.pt successfully.\n",
            "Saved embedding_batches/train_batch_13.pt successfully.\n",
            "Saved embedding_batches/train_batch_14.pt successfully.\n",
            "Saved embedding_batches/train_batch_15.pt successfully.\n",
            "Saved embedding_batches/train_batch_16.pt successfully.\n",
            "Saved embedding_batches/train_batch_17.pt successfully.\n",
            "Saved embedding_batches/train_batch_18.pt successfully.\n",
            "Saved embedding_batches/train_batch_19.pt successfully.\n",
            "Saved embedding_batches/train_batch_20.pt successfully.\n",
            "Saved embedding_batches/train_batch_21.pt successfully.\n",
            "Saved embedding_batches/train_batch_22.pt successfully.\n",
            "Saved embedding_batches/train_batch_23.pt successfully.\n",
            "Saved embedding_batches/train_batch_24.pt successfully.\n",
            "Saved embedding_batches/train_batch_25.pt successfully.\n",
            "Saved embedding_batches/train_batch_26.pt successfully.\n",
            "Saved embedding_batches/train_batch_27.pt successfully.\n",
            "Saved embedding_batches/train_batch_28.pt successfully.\n",
            "Saved embedding_batches/train_batch_29.pt successfully.\n",
            "Saved embedding_batches/train_batch_30.pt successfully.\n",
            "Saved embedding_batches/train_batch_31.pt successfully.\n",
            "Saved embedding_batches/train_batch_32.pt successfully.\n",
            "Saved embedding_batches/train_batch_33.pt successfully.\n",
            "Saved embedding_batches/train_batch_34.pt successfully.\n",
            "Saved embedding_batches/train_batch_35.pt successfully.\n",
            "Saved embedding_batches/train_batch_36.pt successfully.\n",
            "Saved embedding_batches/train_batch_37.pt successfully.\n",
            "Saved embedding_batches/train_batch_38.pt successfully.\n",
            "Saved embedding_batches/train_batch_39.pt successfully.\n",
            "Saved embedding_batches/train_batch_40.pt successfully.\n",
            "Saved embedding_batches/train_batch_41.pt successfully.\n",
            "Saved embedding_batches/train_batch_42.pt successfully.\n",
            "Saved embedding_batches/train_batch_43.pt successfully.\n",
            "Saved embedding_batches/train_batch_44.pt successfully.\n",
            "Saved embedding_batches/train_batch_45.pt successfully.\n",
            "Saved embedding_batches/train_batch_46.pt successfully.\n",
            "Saved embedding_batches/train_batch_47.pt successfully.\n",
            "Saved embedding_batches/train_batch_48.pt successfully.\n",
            "Saved embedding_batches/train_batch_49.pt successfully.\n",
            "Saved embedding_batches/train_batch_50.pt successfully.\n",
            "Saved embedding_batches/train_batch_51.pt successfully.\n",
            "Saved embedding_batches/train_batch_52.pt successfully.\n",
            "Saved embedding_batches/train_batch_53.pt successfully.\n",
            "Saved embedding_batches/train_batch_54.pt successfully.\n",
            "Saved embedding_batches/train_batch_55.pt successfully.\n",
            "Saved embedding_batches/train_batch_56.pt successfully.\n",
            "Saved embedding_batches/train_batch_57.pt successfully.\n",
            "Saved embedding_batches/train_batch_58.pt successfully.\n",
            "Saved embedding_batches/train_batch_59.pt successfully.\n",
            "Saved embedding_batches/train_batch_60.pt successfully.\n",
            "Saved embedding_batches/train_batch_61.pt successfully.\n",
            "Saved embedding_batches/train_batch_62.pt successfully.\n",
            "Saved embedding_batches/train_batch_63.pt successfully.\n",
            "Saved embedding_batches/train_batch_64.pt successfully.\n",
            "Saved embedding_batches/train_batch_65.pt successfully.\n",
            "Saved embedding_batches/train_batch_66.pt successfully.\n",
            "Saved embedding_batches/train_batch_67.pt successfully.\n",
            "Saved embedding_batches/train_batch_68.pt successfully.\n",
            "Saved embedding_batches/train_batch_69.pt successfully.\n",
            "Saved embedding_batches/train_batch_70.pt successfully.\n",
            "Saved embedding_batches/train_batch_71.pt successfully.\n",
            "Saved embedding_batches/train_batch_72.pt successfully.\n",
            "Saved embedding_batches/train_batch_73.pt successfully.\n",
            "Saved embedding_batches/train_batch_74.pt successfully.\n",
            "Saved embedding_batches/train_batch_75.pt successfully.\n",
            "Saved embedding_batches/train_batch_76.pt successfully.\n",
            "Saved embedding_batches/train_batch_77.pt successfully.\n",
            "Saved embedding_batches/train_batch_78.pt successfully.\n",
            "Saved embedding_batches/train_batch_79.pt successfully.\n",
            "Saved embedding_batches/train_batch_80.pt successfully.\n",
            "Saved embedding_batches/train_batch_81.pt successfully.\n",
            "Saved embedding_batches/train_batch_82.pt successfully.\n",
            "Saved embedding_batches/train_batch_83.pt successfully.\n",
            "Saved embedding_batches/train_batch_84.pt successfully.\n",
            "Saved embedding_batches/train_batch_85.pt successfully.\n",
            "Saved embedding_batches/train_batch_86.pt successfully.\n",
            "Saved embedding_batches/train_batch_87.pt successfully.\n",
            "Saved embedding_batches/train_batch_88.pt successfully.\n",
            "Saved embedding_batches/train_batch_89.pt successfully.\n",
            "Saved embedding_batches/train_batch_90.pt successfully.\n",
            "Saved embedding_batches/train_batch_91.pt successfully.\n",
            "Saved embedding_batches/train_batch_92.pt successfully.\n",
            "Saved embedding_batches/train_batch_93.pt successfully.\n",
            "Saved embedding_batches/train_batch_94.pt successfully.\n",
            "Saved embedding_batches/train_batch_95.pt successfully.\n",
            "Saved embedding_batches/train_batch_96.pt successfully.\n",
            "Saved embedding_batches/train_batch_97.pt successfully.\n",
            "Saved embedding_batches/train_batch_98.pt successfully.\n",
            "Saved embedding_batches/train_batch_99.pt successfully.\n",
            "Saved embedding_batches/train_batch_100.pt successfully.\n",
            "Saved embedding_batches/train_batch_101.pt successfully.\n",
            "Saved embedding_batches/train_batch_102.pt successfully.\n",
            "Saved embedding_batches/train_batch_103.pt successfully.\n",
            "Saved embedding_batches/train_batch_104.pt successfully.\n",
            "Saved embedding_batches/train_batch_105.pt successfully.\n",
            "Saved embedding_batches/train_batch_106.pt successfully.\n",
            "Saved embedding_batches/train_batch_107.pt successfully.\n",
            "Saved embedding_batches/train_batch_108.pt successfully.\n",
            "Saved embedding_batches/train_batch_109.pt successfully.\n",
            "Saved embedding_batches/train_batch_110.pt successfully.\n",
            "Saved embedding_batches/train_batch_111.pt successfully.\n",
            "Saved embedding_batches/train_batch_112.pt successfully.\n",
            "Saved embedding_batches/train_batch_113.pt successfully.\n",
            "Saved embedding_batches/train_batch_114.pt successfully.\n",
            "Saved embedding_batches/train_batch_115.pt successfully.\n",
            "Saved embedding_batches/train_batch_116.pt successfully.\n",
            "Saved embedding_batches/train_batch_117.pt successfully.\n",
            "Saved embedding_batches/train_batch_118.pt successfully.\n",
            "Saved embedding_batches/train_batch_119.pt successfully.\n",
            "Saved embedding_batches/train_batch_120.pt successfully.\n",
            "Saved embedding_batches/train_batch_121.pt successfully.\n",
            "Saved embedding_batches/train_batch_122.pt successfully.\n",
            "Saved embedding_batches/train_batch_123.pt successfully.\n",
            "Saved embedding_batches/train_batch_124.pt successfully.\n",
            "Saved embedding_batches/train_batch_125.pt successfully.\n",
            "Saved embedding_batches/train_batch_126.pt successfully.\n",
            "Saved embedding_batches/train_batch_127.pt successfully.\n",
            "Saved embedding_batches/train_batch_128.pt successfully.\n",
            "Saved embedding_batches/train_batch_129.pt successfully.\n",
            "Saved embedding_batches/train_batch_130.pt successfully.\n",
            "Saved embedding_batches/train_batch_131.pt successfully.\n",
            "Saved embedding_batches/train_batch_132.pt successfully.\n",
            "Saved embedding_batches/train_batch_133.pt successfully.\n",
            "Saved embedding_batches/train_batch_134.pt successfully.\n",
            "Saved embedding_batches/train_batch_135.pt successfully.\n",
            "Saved embedding_batches/train_batch_136.pt successfully.\n",
            "Saved embedding_batches/train_batch_137.pt successfully.\n",
            "Saved embedding_batches/train_batch_138.pt successfully.\n",
            "Saved embedding_batches/train_batch_139.pt successfully.\n",
            "Saved embedding_batches/train_batch_140.pt successfully.\n",
            "Saved embedding_batches/train_batch_141.pt successfully.\n",
            "Saved embedding_batches/train_batch_142.pt successfully.\n",
            "Saved embedding_batches/train_batch_143.pt successfully.\n",
            "Saved embedding_batches/train_batch_144.pt successfully.\n",
            "Saved embedding_batches/train_batch_145.pt successfully.\n",
            "Saved embedding_batches/train_batch_146.pt successfully.\n",
            "Saved embedding_batches/train_batch_147.pt successfully.\n",
            "Saved embedding_batches/train_batch_148.pt successfully.\n",
            "Saved embedding_batches/train_batch_149.pt successfully.\n",
            "Saved embedding_batches/train_batch_150.pt successfully.\n",
            "Saved embedding_batches/train_batch_151.pt successfully.\n",
            "Saved embedding_batches/train_batch_152.pt successfully.\n",
            "Saved embedding_batches/train_batch_153.pt successfully.\n",
            "Saved embedding_batches/train_batch_154.pt successfully.\n",
            "Saved embedding_batches/train_batch_155.pt successfully.\n",
            "Saved embedding_batches/train_batch_156.pt successfully.\n",
            "Saved embedding_batches/train_batch_157.pt successfully.\n",
            "Saved embedding_batches/train_batch_158.pt successfully.\n",
            "Saved embedding_batches/train_batch_159.pt successfully.\n",
            "Saved embedding_batches/train_batch_160.pt successfully.\n",
            "Saved embedding_batches/train_batch_161.pt successfully.\n",
            "Saved embedding_batches/train_batch_162.pt successfully.\n",
            "Saved embedding_batches/train_batch_163.pt successfully.\n",
            "Saved embedding_batches/train_batch_164.pt successfully.\n",
            "Saved embedding_batches/train_batch_165.pt successfully.\n",
            "Saved embedding_batches/train_batch_166.pt successfully.\n",
            "Saved embedding_batches/train_batch_167.pt successfully.\n",
            "Saved embedding_batches/train_batch_168.pt successfully.\n",
            "Saved embedding_batches/train_batch_169.pt successfully.\n",
            "Saved embedding_batches/train_batch_170.pt successfully.\n",
            "Saved embedding_batches/train_batch_171.pt successfully.\n",
            "Saved embedding_batches/train_batch_172.pt successfully.\n",
            "Saved embedding_batches/train_batch_173.pt successfully.\n",
            "Saved embedding_batches/train_batch_174.pt successfully.\n",
            "Saved embedding_batches/train_batch_175.pt successfully.\n",
            "Saved embedding_batches/train_batch_176.pt successfully.\n",
            "Saved embedding_batches/train_batch_177.pt successfully.\n",
            "Saved embedding_batches/train_batch_178.pt successfully.\n",
            "Saved embedding_batches/train_batch_179.pt successfully.\n",
            "Saved embedding_batches/train_batch_180.pt successfully.\n",
            "Saved embedding_batches/train_batch_181.pt successfully.\n",
            "Saved embedding_batches/train_batch_182.pt successfully.\n",
            "Saved embedding_batches/train_batch_183.pt successfully.\n",
            "Saved embedding_batches/train_batch_184.pt successfully.\n",
            "Saved embedding_batches/train_batch_185.pt successfully.\n",
            "Saved embedding_batches/train_batch_186.pt successfully.\n",
            "Saved embedding_batches/train_batch_187.pt successfully.\n",
            "Saved embedding_batches/train_batch_188.pt successfully.\n",
            "Saved embedding_batches/train_batch_189.pt successfully.\n",
            "Saved embedding_batches/train_batch_190.pt successfully.\n",
            "Saved embedding_batches/train_batch_191.pt successfully.\n",
            "Saved embedding_batches/train_batch_192.pt successfully.\n",
            "Saved embedding_batches/train_batch_193.pt successfully.\n",
            "Saved embedding_batches/train_batch_194.pt successfully.\n",
            "Saved embedding_batches/train_batch_195.pt successfully.\n",
            "Saved embedding_batches/train_batch_196.pt successfully.\n",
            "Saved embedding_batches/train_batch_197.pt successfully.\n",
            "Saved embedding_batches/train_batch_198.pt successfully.\n",
            "Saved embedding_batches/train_batch_199.pt successfully.\n",
            "Saved embedding_batches/train_batch_200.pt successfully.\n",
            "Saved embedding_batches/train_batch_201.pt successfully.\n",
            "Saved embedding_batches/train_batch_202.pt successfully.\n",
            "Saved embedding_batches/train_batch_203.pt successfully.\n",
            "Saved embedding_batches/train_batch_204.pt successfully.\n",
            "Saved embedding_batches/train_batch_205.pt successfully.\n",
            "Saved embedding_batches/train_batch_206.pt successfully.\n",
            "Saved embedding_batches/train_batch_207.pt successfully.\n",
            "Saved embedding_batches/train_batch_208.pt successfully.\n",
            "Saved embedding_batches/train_batch_209.pt successfully.\n",
            "Saved embedding_batches/train_batch_210.pt successfully.\n",
            "Saved embedding_batches/train_batch_211.pt successfully.\n",
            "Saved embedding_batches/train_batch_212.pt successfully.\n",
            "Saved embedding_batches/train_batch_213.pt successfully.\n",
            "Saved embedding_batches/train_batch_214.pt successfully.\n",
            "Saved embedding_batches/train_batch_215.pt successfully.\n",
            "Saved embedding_batches/train_batch_216.pt successfully.\n",
            "Saved embedding_batches/train_batch_217.pt successfully.\n",
            "Saved embedding_batches/train_batch_218.pt successfully.\n",
            "Saved embedding_batches/train_batch_219.pt successfully.\n",
            "Saved embedding_batches/train_batch_220.pt successfully.\n",
            "Saved embedding_batches/train_batch_221.pt successfully.\n",
            "Saved embedding_batches/train_batch_222.pt successfully.\n",
            "Saved embedding_batches/train_batch_223.pt successfully.\n",
            "Saved embedding_batches/train_batch_224.pt successfully.\n",
            "Saved embedding_batches/train_batch_225.pt successfully.\n",
            "Saved embedding_batches/train_batch_226.pt successfully.\n",
            "Saved embedding_batches/train_batch_227.pt successfully.\n",
            "Saved embedding_batches/train_batch_228.pt successfully.\n",
            "Saved embedding_batches/train_batch_229.pt successfully.\n",
            "Saved embedding_batches/train_batch_230.pt successfully.\n",
            "Saved embedding_batches/train_batch_231.pt successfully.\n",
            "Saved embedding_batches/train_batch_232.pt successfully.\n",
            "Saved embedding_batches/train_batch_233.pt successfully.\n",
            "Saved embedding_batches/train_batch_234.pt successfully.\n",
            "Saved embedding_batches/train_batch_235.pt successfully.\n",
            "Saved embedding_batches/train_batch_236.pt successfully.\n",
            "Saved embedding_batches/train_batch_237.pt successfully.\n",
            "Saved embedding_batches/train_batch_238.pt successfully.\n",
            "Saved embedding_batches/train_batch_239.pt successfully.\n",
            "Saved embedding_batches/train_batch_240.pt successfully.\n",
            "Saved embedding_batches/train_batch_241.pt successfully.\n",
            "Saved embedding_batches/train_batch_242.pt successfully.\n",
            "Saved embedding_batches/train_batch_243.pt successfully.\n",
            "Saved embedding_batches/train_batch_244.pt successfully.\n",
            "Saved embedding_batches/train_batch_245.pt successfully.\n",
            "Saved embedding_batches/train_batch_246.pt successfully.\n",
            "Saved embedding_batches/train_batch_247.pt successfully.\n",
            "Saved embedding_batches/train_batch_248.pt successfully.\n",
            "Saved embedding_batches/train_batch_249.pt successfully.\n",
            "Saved embedding_batches/train_batch_250.pt successfully.\n",
            "Saved embedding_batches/train_batch_251.pt successfully.\n",
            "Saved embedding_batches/train_batch_252.pt successfully.\n",
            "Saved embedding_batches/train_batch_253.pt successfully.\n",
            "Saved embedding_batches/train_batch_254.pt successfully.\n",
            "Saved embedding_batches/train_batch_255.pt successfully.\n",
            "Saved embedding_batches/train_batch_256.pt successfully.\n",
            "Saved embedding_batches/train_batch_257.pt successfully.\n",
            "Saved embedding_batches/train_batch_258.pt successfully.\n",
            "Saved embedding_batches/train_batch_259.pt successfully.\n",
            "Saved embedding_batches/train_batch_260.pt successfully.\n",
            "Saved embedding_batches/train_batch_261.pt successfully.\n",
            "Saved embedding_batches/train_batch_262.pt successfully.\n",
            "Saved embedding_batches/train_batch_263.pt successfully.\n",
            "Saved embedding_batches/train_batch_264.pt successfully.\n",
            "Saved embedding_batches/train_batch_265.pt successfully.\n",
            "Saved embedding_batches/train_batch_266.pt successfully.\n",
            "Saved embedding_batches/train_batch_267.pt successfully.\n",
            "Saved embedding_batches/train_batch_268.pt successfully.\n",
            "Saved embedding_batches/train_batch_269.pt successfully.\n",
            "Saved embedding_batches/train_batch_270.pt successfully.\n",
            "Saved embedding_batches/train_batch_271.pt successfully.\n",
            "Saved embedding_batches/train_batch_272.pt successfully.\n",
            "Saved embedding_batches/train_batch_273.pt successfully.\n",
            "Saved embedding_batches/train_batch_274.pt successfully.\n",
            "Saved embedding_batches/train_batch_275.pt successfully.\n",
            "Saved embedding_batches/train_batch_276.pt successfully.\n",
            "Saved embedding_batches/train_batch_277.pt successfully.\n",
            "Saved embedding_batches/train_batch_278.pt successfully.\n",
            "Saved embedding_batches/train_batch_279.pt successfully.\n",
            "Saved embedding_batches/train_batch_280.pt successfully.\n",
            "Saved embedding_batches/train_batch_281.pt successfully.\n",
            "Saved embedding_batches/train_batch_282.pt successfully.\n",
            "Saved embedding_batches/train_batch_283.pt successfully.\n",
            "Saved embedding_batches/train_batch_284.pt successfully.\n",
            "Saved embedding_batches/train_batch_285.pt successfully.\n",
            "Saved embedding_batches/train_batch_286.pt successfully.\n",
            "Saved embedding_batches/train_batch_287.pt successfully.\n",
            "Saved embedding_batches/train_batch_288.pt successfully.\n",
            "Saved embedding_batches/train_batch_289.pt successfully.\n",
            "Saved embedding_batches/train_batch_290.pt successfully.\n",
            "Saved embedding_batches/train_batch_291.pt successfully.\n",
            "Saved embedding_batches/train_batch_292.pt successfully.\n",
            "Saved embedding_batches/train_batch_293.pt successfully.\n",
            "Saved embedding_batches/train_batch_294.pt successfully.\n",
            "Saved embedding_batches/train_batch_295.pt successfully.\n",
            "Saved embedding_batches/train_batch_296.pt successfully.\n",
            "Saved embedding_batches/train_batch_297.pt successfully.\n",
            "Saved embedding_batches/train_batch_298.pt successfully.\n",
            "Saved embedding_batches/train_batch_299.pt successfully.\n",
            "Saved embedding_batches/train_batch_300.pt successfully.\n",
            "Saved embedding_batches/train_batch_301.pt successfully.\n",
            "Saved embedding_batches/train_batch_302.pt successfully.\n",
            "Saved embedding_batches/train_batch_303.pt successfully.\n",
            "Saved embedding_batches/train_batch_304.pt successfully.\n",
            "Saved embedding_batches/train_batch_305.pt successfully.\n",
            "Saved embedding_batches/train_batch_306.pt successfully.\n",
            "Saved embedding_batches/train_batch_307.pt successfully.\n",
            "Saved embedding_batches/train_batch_308.pt successfully.\n",
            "Saved embedding_batches/train_batch_309.pt successfully.\n",
            "Saved embedding_batches/train_batch_310.pt successfully.\n",
            "Saved embedding_batches/train_batch_311.pt successfully.\n",
            "Saved embedding_batches/train_batch_312.pt successfully.\n",
            "Saved embedding_batches/train_batch_313.pt successfully.\n",
            "Saved embedding_batches/train_batch_314.pt successfully.\n",
            "Saved embedding_batches/train_batch_315.pt successfully.\n",
            "Saved embedding_batches/train_batch_316.pt successfully.\n",
            "Saved embedding_batches/train_batch_317.pt successfully.\n",
            "Saved embedding_batches/train_batch_318.pt successfully.\n",
            "Saved embedding_batches/train_batch_319.pt successfully.\n",
            "Saved embedding_batches/train_batch_320.pt successfully.\n",
            "Saved embedding_batches/train_batch_321.pt successfully.\n",
            "Saved embedding_batches/train_batch_322.pt successfully.\n",
            "Saved embedding_batches/train_batch_323.pt successfully.\n",
            "Saved embedding_batches/train_batch_324.pt successfully.\n",
            "Saved embedding_batches/train_batch_325.pt successfully.\n",
            "Saved embedding_batches/train_batch_326.pt successfully.\n",
            "Saved embedding_batches/train_batch_327.pt successfully.\n",
            "Saved embedding_batches/train_batch_328.pt successfully.\n",
            "Saved embedding_batches/train_batch_329.pt successfully.\n",
            "Saved embedding_batches/train_batch_330.pt successfully.\n",
            "Saved embedding_batches/train_batch_331.pt successfully.\n",
            "Saved embedding_batches/train_batch_332.pt successfully.\n",
            "Saved embedding_batches/train_batch_333.pt successfully.\n",
            "Saved embedding_batches/train_batch_334.pt successfully.\n",
            "Saved embedding_batches/train_batch_335.pt successfully.\n",
            "Saved embedding_batches/train_batch_336.pt successfully.\n",
            "Saved embedding_batches/train_batch_337.pt successfully.\n",
            "Saved embedding_batches/train_batch_338.pt successfully.\n",
            "Saved embedding_batches/train_batch_339.pt successfully.\n",
            "Saved embedding_batches/train_batch_340.pt successfully.\n",
            "Saved embedding_batches/train_batch_341.pt successfully.\n",
            "Saved embedding_batches/train_batch_342.pt successfully.\n",
            "Saved embedding_batches/train_batch_343.pt successfully.\n",
            "Saved embedding_batches/train_batch_344.pt successfully.\n",
            "Saved embedding_batches/train_batch_345.pt successfully.\n",
            "Saved embedding_batches/train_batch_346.pt successfully.\n",
            "Saved embedding_batches/train_batch_347.pt successfully.\n",
            "Saved embedding_batches/train_batch_348.pt successfully.\n",
            "Saved embedding_batches/train_batch_349.pt successfully.\n",
            "Saved embedding_batches/train_batch_350.pt successfully.\n",
            "Saved embedding_batches/train_batch_351.pt successfully.\n",
            "Saved embedding_batches/train_batch_352.pt successfully.\n",
            "Saved embedding_batches/train_batch_353.pt successfully.\n",
            "Saved embedding_batches/train_batch_354.pt successfully.\n",
            "Saved embedding_batches/train_batch_355.pt successfully.\n",
            "Saved embedding_batches/train_batch_356.pt successfully.\n",
            "Saved embedding_batches/train_batch_357.pt successfully.\n",
            "Saved embedding_batches/train_batch_358.pt successfully.\n",
            "Saved embedding_batches/train_batch_359.pt successfully.\n",
            "Saved embedding_batches/train_batch_360.pt successfully.\n",
            "Saved embedding_batches/train_batch_361.pt successfully.\n",
            "Saved embedding_batches/train_batch_362.pt successfully.\n",
            "Saved embedding_batches/train_batch_363.pt successfully.\n",
            "Saved embedding_batches/train_batch_364.pt successfully.\n",
            "Saved embedding_batches/train_batch_365.pt successfully.\n",
            "Saved embedding_batches/train_batch_366.pt successfully.\n",
            "Saved embedding_batches/train_batch_367.pt successfully.\n",
            "Saved embedding_batches/train_batch_368.pt successfully.\n",
            "Saved embedding_batches/train_batch_369.pt successfully.\n",
            "Saved embedding_batches/train_batch_370.pt successfully.\n",
            "Saved embedding_batches/train_batch_371.pt successfully.\n",
            "Saved embedding_batches/train_batch_372.pt successfully.\n",
            "Saved embedding_batches/train_batch_373.pt successfully.\n",
            "Saved embedding_batches/train_batch_374.pt successfully.\n",
            "Saved embedding_batches/train_batch_375.pt successfully.\n",
            "Saved embedding_batches/train_batch_376.pt successfully.\n",
            "Saved embedding_batches/train_batch_377.pt successfully.\n",
            "Saved embedding_batches/train_batch_378.pt successfully.\n",
            "Saved embedding_batches/train_batch_379.pt successfully.\n",
            "Saved embedding_batches/train_batch_380.pt successfully.\n",
            "Saved embedding_batches/train_batch_381.pt successfully.\n",
            "Saved embedding_batches/train_batch_382.pt successfully.\n",
            "Saved embedding_batches/train_batch_383.pt successfully.\n",
            "Saved embedding_batches/train_batch_384.pt successfully.\n",
            "Saved embedding_batches/train_batch_385.pt successfully.\n",
            "Saved embedding_batches/train_batch_386.pt successfully.\n",
            "Saved embedding_batches/train_batch_387.pt successfully.\n",
            "Saved embedding_batches/train_batch_388.pt successfully.\n",
            "Saved embedding_batches/train_batch_389.pt successfully.\n",
            "Saved embedding_batches/train_batch_390.pt successfully.\n",
            "Saved embedding_batches/train_batch_391.pt successfully.\n",
            "Saved embedding_batches/train_batch_392.pt successfully.\n",
            "Saved embedding_batches/train_batch_393.pt successfully.\n",
            "Saved embedding_batches/train_batch_394.pt successfully.\n",
            "Saved embedding_batches/train_batch_395.pt successfully.\n",
            "Saved embedding_batches/train_batch_396.pt successfully.\n",
            "Saved embedding_batches/train_batch_397.pt successfully.\n",
            "Saved embedding_batches/train_batch_398.pt successfully.\n",
            "Saved embedding_batches/train_batch_399.pt successfully.\n",
            "Saved embedding_batches/train_batch_400.pt successfully.\n",
            "Saved embedding_batches/train_batch_401.pt successfully.\n",
            "Saved embedding_batches/train_batch_402.pt successfully.\n",
            "Saved embedding_batches/train_batch_403.pt successfully.\n",
            "Saved embedding_batches/train_batch_404.pt successfully.\n",
            "Saved embedding_batches/train_batch_405.pt successfully.\n",
            "Saved embedding_batches/train_batch_406.pt successfully.\n",
            "Saved embedding_batches/train_batch_407.pt successfully.\n",
            "Saved embedding_batches/train_batch_408.pt successfully.\n",
            "Saved embedding_batches/train_batch_409.pt successfully.\n",
            "Saved embedding_batches/train_batch_410.pt successfully.\n",
            "Saved embedding_batches/train_batch_411.pt successfully.\n",
            "Saved embedding_batches/train_batch_412.pt successfully.\n",
            "Saved embedding_batches/train_batch_413.pt successfully.\n",
            "Saved embedding_batches/train_batch_414.pt successfully.\n",
            "Saved embedding_batches/train_batch_415.pt successfully.\n",
            "Saved embedding_batches/train_batch_416.pt successfully.\n",
            "Saved embedding_batches/train_batch_417.pt successfully.\n",
            "Saved embedding_batches/train_batch_418.pt successfully.\n",
            "Saved embedding_batches/train_batch_419.pt successfully.\n",
            "Saved embedding_batches/train_batch_420.pt successfully.\n",
            "Saved embedding_batches/train_batch_421.pt successfully.\n",
            "Saved embedding_batches/train_batch_422.pt successfully.\n",
            "Saved embedding_batches/train_batch_423.pt successfully.\n",
            "Saved embedding_batches/train_batch_424.pt successfully.\n",
            "Saved embedding_batches/val_batch_0.pt successfully.\n",
            "Saved embedding_batches/val_batch_1.pt successfully.\n",
            "Saved embedding_batches/val_batch_2.pt successfully.\n",
            "Saved embedding_batches/val_batch_3.pt successfully.\n",
            "Saved embedding_batches/val_batch_4.pt successfully.\n",
            "Saved embedding_batches/val_batch_5.pt successfully.\n",
            "Saved embedding_batches/val_batch_6.pt successfully.\n",
            "Saved embedding_batches/val_batch_7.pt successfully.\n",
            "Saved embedding_batches/val_batch_8.pt successfully.\n",
            "Saved embedding_batches/val_batch_9.pt successfully.\n",
            "Saved embedding_batches/val_batch_10.pt successfully.\n",
            "Saved embedding_batches/val_batch_11.pt successfully.\n",
            "Saved embedding_batches/val_batch_12.pt successfully.\n",
            "Saved embedding_batches/val_batch_13.pt successfully.\n",
            "Saved embedding_batches/val_batch_14.pt successfully.\n",
            "Saved embedding_batches/val_batch_15.pt successfully.\n",
            "Saved embedding_batches/val_batch_16.pt successfully.\n",
            "Saved embedding_batches/val_batch_17.pt successfully.\n",
            "Saved embedding_batches/val_batch_18.pt successfully.\n",
            "Saved embedding_batches/val_batch_19.pt successfully.\n",
            "Saved embedding_batches/val_batch_20.pt successfully.\n",
            "Saved embedding_batches/val_batch_21.pt successfully.\n",
            "Saved embedding_batches/val_batch_22.pt successfully.\n",
            "Saved embedding_batches/val_batch_23.pt successfully.\n",
            "Saved embedding_batches/val_batch_24.pt successfully.\n",
            "Saved embedding_batches/val_batch_25.pt successfully.\n",
            "Saved embedding_batches/val_batch_26.pt successfully.\n",
            "Saved embedding_batches/val_batch_27.pt successfully.\n",
            "Saved embedding_batches/val_batch_28.pt successfully.\n",
            "Saved embedding_batches/val_batch_29.pt successfully.\n",
            "Saved embedding_batches/val_batch_30.pt successfully.\n",
            "Saved embedding_batches/val_batch_31.pt successfully.\n",
            "Saved embedding_batches/val_batch_32.pt successfully.\n",
            "Saved embedding_batches/val_batch_33.pt successfully.\n",
            "Saved embedding_batches/val_batch_34.pt successfully.\n",
            "Saved embedding_batches/val_batch_35.pt successfully.\n",
            "Saved embedding_batches/val_batch_36.pt successfully.\n",
            "Saved embedding_batches/val_batch_37.pt successfully.\n",
            "Saved embedding_batches/val_batch_38.pt successfully.\n",
            "Saved embedding_batches/val_batch_39.pt successfully.\n",
            "Saved embedding_batches/val_batch_40.pt successfully.\n",
            "Saved embedding_batches/val_batch_41.pt successfully.\n",
            "Saved embedding_batches/val_batch_42.pt successfully.\n",
            "Saved embedding_batches/val_batch_43.pt successfully.\n",
            "Saved embedding_batches/val_batch_44.pt successfully.\n",
            "Saved embedding_batches/val_batch_45.pt successfully.\n",
            "Saved embedding_batches/val_batch_46.pt successfully.\n",
            "Saved embedding_batches/val_batch_47.pt successfully.\n",
            "Saved embedding_batches/test_batch_0.pt successfully.\n",
            "Saved embedding_batches/test_batch_1.pt successfully.\n",
            "Saved embedding_batches/test_batch_2.pt successfully.\n",
            "Saved embedding_batches/test_batch_3.pt successfully.\n",
            "Saved embedding_batches/test_batch_4.pt successfully.\n",
            "Saved embedding_batches/test_batch_5.pt successfully.\n",
            "Saved embedding_batches/test_batch_6.pt successfully.\n",
            "Saved embedding_batches/test_batch_7.pt successfully.\n",
            "Saved embedding_batches/test_batch_8.pt successfully.\n",
            "Saved embedding_batches/test_batch_9.pt successfully.\n",
            "Saved embedding_batches/test_batch_10.pt successfully.\n",
            "Saved embedding_batches/test_batch_11.pt successfully.\n",
            "Saved embedding_batches/test_batch_12.pt successfully.\n",
            "Saved embedding_batches/test_batch_13.pt successfully.\n",
            "Saved embedding_batches/test_batch_14.pt successfully.\n",
            "Saved embedding_batches/test_batch_15.pt successfully.\n",
            "Saved embedding_batches/test_batch_16.pt successfully.\n",
            "Saved embedding_batches/test_batch_17.pt successfully.\n",
            "Saved embedding_batches/test_batch_18.pt successfully.\n",
            "Saved embedding_batches/test_batch_19.pt successfully.\n",
            "Saved embedding_batches/test_batch_20.pt successfully.\n",
            "Saved embedding_batches/test_batch_21.pt successfully.\n",
            "Saved embedding_batches/test_batch_22.pt successfully.\n",
            "Saved embedding_batches/test_batch_23.pt successfully.\n",
            "Saved embedding_batches/test_batch_24.pt successfully.\n",
            "Saved embedding_batches/test_batch_25.pt successfully.\n",
            "Saved embedding_batches/test_batch_26.pt successfully.\n",
            "Saved embedding_batches/test_batch_27.pt successfully.\n",
            "Saved embedding_batches/test_batch_28.pt successfully.\n",
            "Saved embedding_batches/test_batch_29.pt successfully.\n",
            "Saved embedding_batches/test_batch_30.pt successfully.\n",
            "Saved embedding_batches/test_batch_31.pt successfully.\n",
            "Saved embedding_batches/test_batch_32.pt successfully.\n",
            "Saved embedding_batches/test_batch_33.pt successfully.\n",
            "Saved embedding_batches/test_batch_34.pt successfully.\n",
            "Saved embedding_batches/test_batch_35.pt successfully.\n",
            "Saved embedding_batches/test_batch_36.pt successfully.\n",
            "Saved embedding_batches/test_batch_37.pt successfully.\n",
            "Saved embedding_batches/test_batch_38.pt successfully.\n",
            "Saved embedding_batches/test_batch_39.pt successfully.\n",
            "Saved embedding_batches/test_batch_40.pt successfully.\n",
            "Saved embedding_batches/test_batch_41.pt successfully.\n",
            "Saved embedding_batches/test_batch_42.pt successfully.\n",
            "Saved embedding_batches/test_batch_43.pt successfully.\n",
            "Saved embedding_batches/test_batch_44.pt successfully.\n",
            "Saved embedding_batches/test_batch_45.pt successfully.\n",
            "Saved embedding_batches/test_batch_46.pt successfully.\n",
            "Saved embedding_batches/test_batch_47.pt successfully.\n",
            "Saved embedding_batches/test_batch_48.pt successfully.\n",
            "Saved embedding_batches/test_batch_49.pt successfully.\n",
            "Saved embedding_batches/test_batch_50.pt successfully.\n",
            "Saved embedding_batches/test_batch_51.pt successfully.\n",
            "Saved embedding_batches/test_batch_52.pt successfully.\n",
            "Embedding Generation & Saving Completed Successfully!\n"
          ]
        }
      ],
      "source": [
        "# ===========================\n",
        "# Feature Engineering - GloVe Embeddings (GPU Optimized)\n",
        "# ===========================\n",
        "\n",
        "glove_model = api.load('glove-twitter-100')\n",
        "embedding_dim = 100\n",
        "max_seq_length = 128\n",
        "batch_size = 2000  # Initial Batch Size (Will Adjust if GPU Memory is Low)\n",
        "embedding_cache = {}\n",
        "os.makedirs('embedding_batches', exist_ok=True)\n",
        "\n",
        "def check_gpu_memory():\n",
        "    # Check available GPU memory\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory\n",
        "        allocated_memory = torch.cuda.memory_allocated(0)\n",
        "        free_memory = gpu_memory - allocated_memory\n",
        "        return free_memory / (1024 ** 3)  # Convert to GB\n",
        "    return None\n",
        "\n",
        "def create_embedding_matrix(texts, batch_name):\n",
        "    global batch_size\n",
        "    total_texts = len(texts)\n",
        "\n",
        "    # Adjust batch size based on available GPU memory\n",
        "    free_memory = check_gpu_memory()\n",
        "    if free_memory and free_memory < 2:  # If less than 2GB is free, reduce batch size\n",
        "        batch_size = max(batch_size // 2, 128)  # Don't go below 128 to avoid slow processing\n",
        "        print(f\"Low GPU Memory - Adjusting batch size to {batch_size}\")\n",
        "\n",
        "    for batch_start in range(0, total_texts, batch_size):\n",
        "        batch_texts = texts[batch_start:batch_start + batch_size]\n",
        "        batch_embeddings = []\n",
        "\n",
        "        for text in batch_texts:\n",
        "            words = text.split()[:max_seq_length]\n",
        "            embeddings = []\n",
        "\n",
        "            for word in words:\n",
        "                if word in embedding_cache:\n",
        "                    embeddings.append(embedding_cache[word])\n",
        "                elif word in glove_model:\n",
        "                    embedding = glove_model[word]\n",
        "                    embedding_cache[word] = embedding\n",
        "                    embeddings.append(embedding)\n",
        "                else:\n",
        "                    embedding = np.zeros(embedding_dim)\n",
        "                    embedding_cache[word] = embedding\n",
        "                    embeddings.append(embedding)\n",
        "\n",
        "            if len(embeddings) < max_seq_length:\n",
        "                embeddings.extend([np.zeros(embedding_dim)] * (max_seq_length - len(embeddings)))\n",
        "\n",
        "            batch_embeddings.append(torch.tensor(np.array(embeddings), dtype=torch.float32, device=device))\n",
        "\n",
        "        batch_file_name = f\"embedding_batches/{batch_name}_batch_{batch_start // batch_size}.pt\"\n",
        "        torch.save(torch.stack(batch_embeddings), batch_file_name)\n",
        "        print(f\"Saved {batch_file_name} successfully.\")\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "create_embedding_matrix(train_texts, 'train')\n",
        "create_embedding_matrix(val_texts, 'val')\n",
        "create_embedding_matrix(test_texts, 'test')\n",
        "\n",
        "print(\"Embedding Generation & Saving Completed Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3aa58d8a-ea9e-46e2-a217-d69f5d3b9081",
      "metadata": {
        "id": "3aa58d8a-ea9e-46e2-a217-d69f5d3b9081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a320217-49a7-4d62-c296-18cc484fd2f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batches Loaded Successfully - Ready for Processing!\n"
          ]
        }
      ],
      "source": [
        "import os  # Importing the 'os' module\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import gc\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def load_embedding_batch(batch_path):\n",
        "    \"\"\"\n",
        "    Load a single batch from disk to avoid memory overload.\n",
        "    \"\"\"\n",
        "    return torch.load(batch_path, map_location=device)\n",
        "\n",
        "def prepare_word2vec_dataloader(batch_paths, labels, batch_size=64):\n",
        "    \"\"\"\n",
        "    Prepare DataLoader that loads one batch at a time during training to avoid memory overload.\n",
        "    \"\"\"\n",
        "    for i, batch_path in enumerate(batch_paths):\n",
        "        # Dynamically load embeddings from disk, one batch at a time\n",
        "        embeddings = load_embedding_batch(batch_path)\n",
        "        num_embeddings = embeddings.size(0)\n",
        "\n",
        "        # Calculate label indices for the current batch\n",
        "        start_idx = i * num_embeddings\n",
        "        end_idx = min(start_idx + num_embeddings, len(labels))\n",
        "\n",
        "        # Load labels for the current batch\n",
        "        batch_labels = torch.tensor(labels[start_idx:end_idx], device=device)\n",
        "\n",
        "        # If embeddings and labels mismatch, adjust them\n",
        "        if len(batch_labels) != num_embeddings:\n",
        "            batch_labels = batch_labels[:num_embeddings]\n",
        "\n",
        "        # Create DataLoader for the current batch\n",
        "        dataset = TensorDataset(embeddings, batch_labels)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        yield dataloader  # Yield DataLoader to avoid memory overload\n",
        "\n",
        "        # Release memory\n",
        "        del embeddings, batch_labels, dataset, dataloader\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "def load_embedding_batches(batch_name):\n",
        "    \"\"\"\n",
        "    Load all embedding batch file paths for a given batch name (train, val, test).\n",
        "    \"\"\"\n",
        "    batch_files = sorted([f for f in os.listdir('embedding_batches') if f.startswith(batch_name)])\n",
        "    batch_paths = [os.path.join('embedding_batches', file) for file in batch_files]\n",
        "    return batch_paths\n",
        "\n",
        "# Load batch paths\n",
        "train_embedding_paths = load_embedding_batches('train')\n",
        "val_embedding_paths = load_embedding_batches('val')\n",
        "test_embedding_paths = load_embedding_batches('test')\n",
        "\n",
        "print('Batches Loaded Successfully - Ready for Processing!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Prepare DataLoaders with Generator Approach\n",
        "# ===========================\n",
        "\n",
        "# Train DataLoader Generator\n",
        "train_loader_w2v = prepare_word2vec_dataloader(train_embedding_paths, train_labels)\n",
        "\n",
        "# Validation DataLoader Generator\n",
        "val_loader_w2v = prepare_word2vec_dataloader(val_embedding_paths, val_labels)\n",
        "\n",
        "# Test DataLoader Generator\n",
        "test_loader_w2v = prepare_word2vec_dataloader(test_embedding_paths, test_labels)\n",
        "\n",
        "print('DataLoaders Prepared Successfully (Lazy Loading Enabled)')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsPVLY94dT-p",
        "outputId": "62620076-549b-4554-88d1-2d48da48d82b"
      },
      "id": "NsPVLY94dT-p",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders Prepared Successfully (Lazy Loading Enabled)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d82ff329-8e7a-49c2-b9d8-fbfb0b2b0062",
      "metadata": {
        "id": "d82ff329-8e7a-49c2-b9d8-fbfb0b2b0062",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e599a5e1-2006-4446-949a-24f359125e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Implementation Completed Successfully!\n"
          ]
        }
      ],
      "source": [
        "# ===========================\n",
        "# Model Definitions (BERT, RNN, LSTM, GRU)\n",
        "# ===========================\n",
        "\n",
        "# ===========================\n",
        "# BERT Model\n",
        "# ===========================\n",
        "\n",
        "class BERTSentimentClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTSentimentClassifier, self).__init__()\n",
        "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return outputs.logits\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# Base Model for RNN, LSTM, and GRU\n",
        "# ===========================\n",
        "\n",
        "class BaseRNNModel(nn.Module):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        super(BaseRNNModel, self).__init__()\n",
        "        vocab_size, embedding_dim = embedding_matrix.shape\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=False)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(128, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# RNN Model\n",
        "# ===========================\n",
        "\n",
        "class RNNSentimentClassifier(BaseRNNModel):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        super(RNNSentimentClassifier, self).__init__(embedding_matrix)\n",
        "        self.rnn = nn.RNN(embedding_matrix.shape[1], 128, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = super().forward(x)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = x[:, -1, :]\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# LSTM Model\n",
        "# ===========================\n",
        "\n",
        "class LSTMSentimentClassifier(BaseRNNModel):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        super(LSTMSentimentClassifier, self).__init__(embedding_matrix)\n",
        "        self.lstm = nn.LSTM(embedding_matrix.shape[1], 128, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = super().forward(x)\n",
        "        x, (h_n, c_n) = self.lstm(x)\n",
        "        x = x[:, -1, :]\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# GRU Model\n",
        "# ===========================\n",
        "\n",
        "class GRUSentimentClassifier(BaseRNNModel):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        super(GRUSentimentClassifier, self).__init__(embedding_matrix)\n",
        "        self.gru = nn.GRU(embedding_matrix.shape[1], 128, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = super().forward(x)\n",
        "        x, h_n = self.gru(x)\n",
        "        x = x[:, -1, :]\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "print('Model Implementation Completed Successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "0188806f-5d3a-4392-acd9-45aa36849022",
      "metadata": {
        "id": "0188806f-5d3a-4392-acd9-45aa36849022"
      },
      "outputs": [],
      "source": [
        "def get_memory_usage():\n",
        "    return psutil.virtual_memory().used / (1024 ** 2)\n",
        "\n",
        "def log_time_and_memory(start_time, start_memory):\n",
        "    end_time = time.time()\n",
        "    end_memory = get_memory_usage()\n",
        "    time_taken = end_time - start_time\n",
        "    memory_used = end_memory - start_memory\n",
        "    return time_taken, memory_used\n",
        "\n",
        "\n",
        "def plot_comparative_barchart(results_df):\n",
        "    metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall', 'ROC-AUC']\n",
        "    results_df[metrics].plot(kind='bar', figsize=(12, 6))\n",
        "    plt.title('Model Performance Comparison')\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('Scores')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, model_name):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'{model_name} - Confusion Matrix')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "304d17f6-f9d4-4e49-9127-99c89d2a96ca",
      "metadata": {
        "id": "304d17f6-f9d4-4e49-9127-99c89d2a96ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "110272d6-86e2-48b5-d6ba-35e1af6ebf97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Training and Evaluation Code Integrated Successfully!\n"
          ]
        }
      ],
      "source": [
        "# # ===========================\n",
        "# # Model Training and Evaluation with GPU Utilization\n",
        "# # ===========================\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=5):\n",
        "     model.to(device)\n",
        "     model.train()\n",
        "     training_losses = []\n",
        "     validation_losses = []\n",
        "\n",
        "     for epoch in range(epochs):\n",
        "         total_loss = 0\n",
        "         correct_predictions = 0\n",
        "\n",
        "         for batch in train_loader:\n",
        "             inputs, masks, labels = [x.to(device) for x in batch]  # Unpack inputs, masks, and labels\n",
        "             optimizer.zero_grad()\n",
        "             outputs = model(inputs, attention_mask=masks)\n",
        "             loss = criterion(outputs, labels)\n",
        "             loss.backward()\n",
        "             optimizer.step()\n",
        "\n",
        "             total_loss += loss.item()\n",
        "             preds = torch.argmax(outputs, dim=1)\n",
        "             correct_predictions += torch.sum(preds == labels).item()\n",
        "\n",
        "         accuracy = correct_predictions / len(train_loader.dataset)\n",
        "         training_losses.append(total_loss / len(train_loader))\n",
        "\n",
        "         # Validation\n",
        "         model.eval()\n",
        "         val_loss = 0\n",
        "         with torch.no_grad():\n",
        "             for val_batch in val_loader:\n",
        "                 val_inputs, val_masks, val_labels = [x.to(device) for x in val_batch]\n",
        "                 val_outputs = model(val_inputs, attention_mask=val_masks)\n",
        "                 val_loss += criterion(val_outputs, val_labels).item()\n",
        "\n",
        "         validation_losses.append(val_loss / len(val_loader))\n",
        "         print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}, Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "     return training_losses, validation_losses\n",
        "\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "     model.to(device)\n",
        "     model.eval()\n",
        "     total_loss = 0\n",
        "     all_preds, all_labels = [], []\n",
        "\n",
        "     with torch.no_grad():\n",
        "         for batch in test_loader:\n",
        "             inputs, masks, labels = [x.to(device) for x in batch]\n",
        "             outputs = model(inputs, attention_mask=masks)\n",
        "             loss = criterion(outputs, labels)\n",
        "             total_loss += loss.item()\n",
        "\n",
        "             preds = torch.argmax(outputs, dim=1)\n",
        "             all_preds.extend(preds.cpu().numpy())\n",
        "             all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "     accuracy = accuracy_score(all_labels, all_preds)\n",
        "     f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "     precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "     recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "     cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "     print(f\"Test Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
        "     return accuracy, f1, precision, recall, cm\n",
        "\n",
        "print(\"Model Training and Evaluation Code Integrated Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Model Training and Evaluation with GPU Utilization\n",
        "# ===========================\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=5):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    training_losses = []\n",
        "    validation_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        correct_predictions = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):  # Add batch_idx\n",
        "            inputs, labels = batch  # Assuming your train_loader provides (inputs, labels)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)  # Removed attention_mask as it's not needed for RNN/LSTM/GRU\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)  # Get predicted labels\n",
        "            correct_predictions += torch.sum(preds == labels).item()\n",
        "\n",
        "        accuracy = correct_predictions / len(train_loader.dataset)  # Assuming train_loader has dataset attribute\n",
        "        training_losses.append(total_loss / len(train_loader))\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for val_batch_idx, val_batch in enumerate(val_loader):  # Add val_batch_idx\n",
        "                val_inputs, val_labels = val_batch  # Assuming val_loader provides (inputs, labels)\n",
        "                val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
        "\n",
        "                val_outputs = model(val_inputs)  # Removed attention_mask\n",
        "                val_loss += criterion(val_outputs, val_labels).item()\n",
        "\n",
        "        validation_losses.append(val_loss / len(val_loader))  # Assuming val_loader has dataset attribute\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}, Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    return training_losses, validation_losses\n",
        "\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(test_loader):  # Add batch_idx\n",
        "            inputs, labels = batch  # Assuming your test_loader provides (inputs, labels)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)  # Removed attention_mask\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)  # Get predicted labels\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    print(f\"Test Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
        "    return accuracy, f1, precision, recall, cm\n",
        "\n",
        "print(\"Model Training and Evaluation Code Integrated Successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL3rgD3ti2rr",
        "outputId": "644d4c80-1716-471e-dd24-cc0b607f52b9"
      },
      "id": "LL3rgD3ti2rr",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Training and Evaluation Code Integrated Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training & Evaluation - Calling Functions"
      ],
      "metadata": {
        "id": "oWIV0b1PjwvG"
      },
      "id": "oWIV0b1PjwvG"
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# DataLoader Preparation\n",
        "# ===========================\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def prepare_dataloader(inputs, masks, labels, batch_size=16):\n",
        "    # Convert inputs, masks, and labels to tensors and ensure they're on CPU before sending to DataLoader\n",
        "        inputs = torch.tensor(inputs, dtype=torch.long)\n",
        "        masks = torch.tensor(masks, dtype=torch.long)\n",
        "        labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    # Verify label range\n",
        "        if not torch.all((labels >= 0) & (labels < 3)):\n",
        "          print(\"Warning: Some labels are outside the expected range [0, 1, 2].\")\n",
        "\n",
        "        dataset = TensorDataset(inputs, masks, labels)\n",
        "        return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "kURLpFe8qL7D"
      },
      "id": "kURLpFe8qL7D",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Prepare DataLoaders for BERT\n",
        "# ===========================\n",
        "\n",
        "# Generate DataLoader objects for training, validation, and testing datasets\n",
        "train_loader = prepare_dataloader(train_inputs.cpu(), train_masks.cpu(), train_labels)\n",
        "val_loader = prepare_dataloader(val_inputs.cpu(), val_masks.cpu(), val_labels)\n",
        "test_loader = prepare_dataloader(test_inputs.cpu(), test_masks.cpu(), test_labels)\n",
        "\n",
        "print(\"DataLoaders Prepared Successfully!\")\n",
        "\n",
        "# ===========================\n",
        "# Train and Evaluate BERT Model (Using Mixed Precision Training)\n",
        "# ===========================\n",
        "\n",
        "model_name = 'BERT'\n",
        "model = BERTSentimentClassifier().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scaler = torch.amp.GradScaler() # Initialize Gradient Scaler for AMP\n",
        "\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "model.train()\n",
        "\n",
        "for epoch in range(5):\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs, masks, labels = [x.to(device) for x in batch]\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.amp.autocast(device_type='cuda'):\n",
        "            outputs = model(inputs, attention_mask=masks)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct_predictions += torch.sum(preds == labels).item()\n",
        "\n",
        "    accuracy = correct_predictions / len(train_loader.dataset)\n",
        "    training_losses.append(total_loss / len(train_loader))\n",
        "    print(f\"Epoch [{epoch+1}/5], Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# ===========================\n",
        "# Evaluation\n",
        "# ===========================\n",
        "accuracy, f1, precision, recall, cm = evaluate_model(model, test_loader, criterion)\n",
        "\n",
        "# ===========================\n",
        "# Store Results\n",
        "# ===========================\n",
        "results = {}\n",
        "results[model_name] = {\n",
        "    'Accuracy': accuracy,\n",
        "    'F1-Score': f1,\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'Confusion Matrix': cm,\n",
        "    'Training Losses': training_losses\n",
        "}\n",
        "\n",
        "print(f\"{model_name} training and evaluation completed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQjXWiiPi7zg",
        "outputId": "46214c45-6d9e-4f0b-aadb-8b9dca5019e3"
      },
      "id": "IQjXWiiPi7zg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-efb16b47909e>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  inputs = torch.tensor(inputs, dtype=torch.long)\n",
            "<ipython-input-26-efb16b47909e>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  masks = torch.tensor(masks, dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders Prepared Successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 15461.3591, Accuracy: 0.8783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "model_name = 'RNN'\n",
        "embedding_matrix = torch.tensor(next(iter(train_loader_w2v))[0].detach().cpu().numpy())\n",
        "model = RNNSentimentClassifier(embedding_matrix).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training\n",
        "training_losses, validation_losses = [], []\n",
        "\n",
        "for train_dataloader in train_loader_w2v:\n",
        "    train_loss, val_loss = train_model(\n",
        "        model,\n",
        "        train_dataloader,\n",
        "        val_loader_w2v,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        epochs=5\n",
        "    )\n",
        "    training_losses.extend(train_loss)\n",
        "    validation_losses.extend(val_loss)\n",
        "\n",
        "# Evaluation\n",
        "all_accuracies, all_f1_scores, all_precisions, all_recalls, all_cms = [], [], [], [], []\n",
        "\n",
        "for test_dataloader in test_loader_w2v:\n",
        "    accuracy, f1, precision, recall, cm = evaluate_model(\n",
        "        model,\n",
        "        test_dataloader,\n",
        "        criterion\n",
        "    )\n",
        "    all_accuracies.append(accuracy)\n",
        "    all_f1_scores.append(f1)\n",
        "    all_precisions.append(precision)\n",
        "    all_recalls.append(recall)\n",
        "    all_cms.append(cm)\n",
        "\n",
        "# Aggregate Metrics\n",
        "accuracy = sum(all_accuracies) / len(all_accuracies)\n",
        "f1 = sum(all_f1_scores) / len(all_f1_scores)\n",
        "precision = sum(all_precisions) / len(all_precisions)\n",
        "recall = sum(all_recalls) / len(all_recalls)\n",
        "cm = sum(all_cms)\n",
        "\n",
        "# Store Results\n",
        "results[model_name] = {\n",
        "    'Accuracy': accuracy,\n",
        "    'F1-Score': f1,\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'Confusion Matrix': cm,\n",
        "    'Training Losses': training_losses,\n",
        "    'Validation Losses': validation_losses\n",
        "}\n",
        "\n",
        "print(f\"{model_name} training and evaluation completed successfully!\")"
      ],
      "metadata": {
        "id": "UecKTA4anvQT"
      },
      "id": "UecKTA4anvQT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Prepare DataLoaders for BERT\n",
        "# ===========================\n",
        "\n",
        "# Generate DataLoader objects for training, validation, and testing datasets\n",
        "train_loader = prepare_dataloader(train_inputs.cpu(), train_masks.cpu(), train_labels)\n",
        "val_loader = prepare_dataloader(val_inputs, val_masks, val_labels)\n",
        "test_loader = prepare_dataloader(test_inputs, test_masks, test_labels)\n",
        "\n",
        "print(\"DataLoaders Prepared Successfully!\")\n",
        "\n",
        "# ===========================\n",
        "# Train and Evaluate BERT Model (Using Mixed Precision Training)\n",
        "# ===========================\n",
        "\n",
        "model_name = 'BERT'\n",
        "model = BERTSentimentClassifier().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scaler = torch.amp.GradScaler() # Initialize Gradient Scaler for AMP\n",
        "\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "model.train()\n",
        "\n",
        "for epoch in range(5):\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs, masks, labels = [x.to(device) for x in batch]\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.amp.autocast(device_type='cuda'):\n",
        "            outputs = model(inputs, attention_mask=masks)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        correct_predictions += torch.sum(preds == labels).item()\n",
        "\n",
        "    accuracy = correct_predictions / len(train_loader.dataset)\n",
        "    training_losses.append(total_loss / len(train_loader))\n",
        "    print(f\"Epoch [{epoch+1}/5], Loss: {total_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# ===========================\n",
        "# Evaluation\n",
        "# ===========================\n",
        "accuracy, f1, precision, recall, cm = evaluate_model(model, test_loader, criterion)\n",
        "\n",
        "# ===========================\n",
        "# Store Results\n",
        "# ===========================\n",
        "results = {}\n",
        "results[model_name] = {\n",
        "    'Accuracy': accuracy,\n",
        "    'F1-Score': f1,\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'Confusion Matrix': cm,\n",
        "    'Training Losses': training_losses\n",
        "}\n",
        "\n",
        "print(f\"{model_name} training and evaluation completed successfully!\")"
      ],
      "metadata": {
        "id": "9255W4tpi8CT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "ffcc3bbb-703c-441c-9591-28d6f0177130"
      },
      "id": "9255W4tpi8CT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-efb16b47909e>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  inputs = torch.tensor(inputs, dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-ce0943de0bd0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Generate DataLoader objects for training, validation, and testing datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-efb16b47909e>\u001b[0m in \u001b[0;36mprepare_dataloader\u001b[0;34m(inputs, masks, labels, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Convert inputs, masks, and labels to tensors and ensure they're on CPU before sending to DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you have a 'results' dictionary if not already initialized\n",
        "if 'results' not in globals():\n",
        "    results = {}\n",
        "\n",
        "model_name = 'LSTM'\n",
        "\n",
        "# Retrieve the embedding matrix from the first batch of train_loader_w2v\n",
        "embedding_matrix = torch.tensor(next(iter(train_loader_w2v))[0].detach().cpu().numpy())\n",
        "model = LSTMSentimentClassifier(embedding_matrix).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training\n",
        "training_losses, validation_losses = [], []\n",
        "\n",
        "for train_dataloader in train_loader_w2v:\n",
        "    train_loss, val_loss = train_model(\n",
        "        model,\n",
        "        train_dataloader,\n",
        "        val_loader_w2v,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        epochs=5\n",
        "    )\n",
        "    training_losses.extend(train_loss)\n",
        "    validation_losses.extend(val_loss)\n",
        "\n",
        "# Evaluation\n",
        "all_accuracies, all_f1_scores, all_precisions, all_recalls, all_cms = [], [], [], [], []\n",
        "\n",
        "for test_dataloader in test_loader_w2v:\n",
        "    accuracy, f1, precision, recall, cm = evaluate_model(\n",
        "        model,\n",
        "        test_dataloader,\n",
        "        criterion\n",
        "    )\n",
        "    all_accuracies.append(accuracy)\n",
        "    all_f1_scores.append(f1)\n",
        "    all_precisions.append(precision)\n",
        "    all_recalls.append(recall)\n",
        "    all_cms.append(cm)\n",
        "\n",
        "# Aggregate Metrics\n",
        "accuracy = sum(all_accuracies) / len(all_accuracies)\n",
        "f1 = sum(all_f1_scores) / len(all_f1_scores)\n",
        "precision = sum(all_precisions) / len(all_precisions)\n",
        "recall = sum(all_recalls) / len(all_recalls)\n",
        "cm = sum(all_cms)\n",
        "\n",
        "# Store Results\n",
        "results[model_name] = {\n",
        "    'Accuracy': accuracy,\n",
        "    'F1-Score': f1,\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'Confusion Matrix': cm,\n",
        "    'Training Losses': training_losses,\n",
        "    'Validation Losses': validation_losses\n",
        "}\n",
        "\n",
        "print(f\"{model_name} training and evaluation completed successfully!\")"
      ],
      "metadata": {
        "id": "VtQLcJgti8Mk"
      },
      "id": "VtQLcJgti8Mk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure you have a 'results' dictionary if not already initialized\n",
        "if 'results' not in globals():\n",
        "    results = {}\n",
        "\n",
        "model_name = 'GRU'\n",
        "\n",
        "# Retrieve the embedding matrix from the first batch of train_loader_w2v\n",
        "embedding_matrix = torch.tensor(next(iter(train_loader_w2v))[0].detach().cpu().numpy())\n",
        "model = GRUSentimentClassifier(embedding_matrix).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training\n",
        "training_losses, validation_losses = [], []\n",
        "\n",
        "for train_dataloader in train_loader_w2v:\n",
        "    train_loss, val_loss = train_model(\n",
        "        model,\n",
        "        train_dataloader,\n",
        "        val_loader_w2v,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        epochs=5\n",
        "    )\n",
        "    training_losses.extend(train_loss)\n",
        "    validation_losses.extend(val_loss)\n",
        "\n",
        "# Evaluation\n",
        "all_accuracies, all_f1_scores, all_precisions, all_recalls, all_cms = [], [], [], [], []\n",
        "\n",
        "for test_dataloader in test_loader_w2v:\n",
        "    accuracy, f1, precision, recall, cm = evaluate_model(\n",
        "        model,\n",
        "        test_dataloader,\n",
        "        criterion\n",
        "    )\n",
        "    all_accuracies.append(accuracy)\n",
        "    all_f1_scores.append(f1)\n",
        "    all_precisions.append(precision)\n",
        "    all_recalls.append(recall)\n",
        "    all_cms.append(cm)\n",
        "\n",
        "# Aggregate Metrics\n",
        "accuracy = sum(all_accuracies) / len(all_accuracies)\n",
        "f1 = sum(all_f1_scores) / len(all_f1_scores)\n",
        "precision = sum(all_precisions) / len(all_precisions)\n",
        "recall = sum(all_recalls) / len(all_recalls)\n",
        "cm = sum(all_cms)\n",
        "\n",
        "# Store Results\n",
        "results[model_name] = {\n",
        "    'Accuracy': accuracy,\n",
        "    'F1-Score': f1,\n",
        "    'Precision': precision,\n",
        "    'Recall': recall,\n",
        "    'Confusion Matrix': cm,\n",
        "    'Training Losses': training_losses,\n",
        "    'Validation Losses': validation_losses\n",
        "}\n",
        "\n",
        "print(f\"{model_name} training and evaluation completed successfully!\")"
      ],
      "metadata": {
        "id": "LVcMC7Uri3kH"
      },
      "id": "LVcMC7Uri3kH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "414e1fcc-f0c0-49c3-8b19-5d62ec46b1f3",
      "metadata": {
        "id": "414e1fcc-f0c0-49c3-8b19-5d62ec46b1f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016d3691-d93d-4880-d093-60ba5dfca56c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation & Comparison Completed Successfully!\n"
          ]
        }
      ],
      "source": [
        "def plot_confusion_matrix(cm, model_name):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'{model_name} - Confusion Matrix')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.show()\n",
        "\n",
        "def compare_models(results):\n",
        "    # Convert results dictionary to DataFrame for comparison\n",
        "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "\n",
        "    # Display overall comparison report\n",
        "    print(\"\\nComparative Analysis Report:\")\n",
        "    print(results_df[['Accuracy', 'F1-Score', 'Precision', 'Recall']])\n",
        "\n",
        "    # Plotting Bar Chart for Performance Comparison\n",
        "    results_df[['Accuracy', 'F1-Score', 'Precision', 'Recall']].plot(kind='bar', figsize=(12, 6))\n",
        "    plt.title('Model Performance Comparison')\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('Scores')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "    # Visualize Confusion Matrices and Loss Curves for Each Model\n",
        "    for model_name, metrics in results.items():\n",
        "        # Plot Confusion Matrix\n",
        "        plot_confusion_matrix(metrics['Confusion Matrix'], model_name)\n",
        "\n",
        "        # Plot Training & Validation Loss\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(metrics['Training Losses'], label='Training Loss')\n",
        "        plt.plot(metrics['Validation Losses'], label='Validation Loss')\n",
        "        plt.title(f'{model_name} - Training & Validation Loss Over Epochs')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"Comparison Completed Successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8fc1ddf-a4ca-4d82-9b5f-3d0f3486b48c",
      "metadata": {
        "id": "f8fc1ddf-a4ca-4d82-9b5f-3d0f3486b48c"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "def add_model_results(model_name, accuracy, f1, precision, recall, roc_auc, time_taken, memory_used, training_losses, validation_losses, cm):\n",
        "    results[model_name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'F1-Score': f1,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'ROC-AUC': roc_auc,\n",
        "        'Training Time (s)': time_taken,\n",
        "        'Memory Usage (MB)': memory_used,\n",
        "        'Training Losses': training_losses,\n",
        "        'Validation Losses': validation_losses,\n",
        "        'Confusion Matrix': cm\n",
        "    }\n",
        "\n",
        "print(\"Result Storage Function Created Successfully!\")\n",
        "\n",
        "# Example of adding model results. Make sure to replace the metric variables for each model.\n",
        "\n",
        "# For BERT\n",
        "add_model_results(\n",
        "    model_name='BERT',\n",
        "    accuracy=bert_accuracy,\n",
        "    f1=bert_f1,\n",
        "    precision=bert_precision,\n",
        "    recall=bert_recall,\n",
        "    roc_auc=bert_roc_auc,\n",
        "    time_taken=bert_time_taken,\n",
        "    memory_used=bert_memory_used,\n",
        "    training_losses=bert_training_losses,\n",
        "    validation_losses=bert_validation_losses,\n",
        "    cm=bert_cm\n",
        ")\n",
        "\n",
        "# For RNN\n",
        "add_model_results(\n",
        "    model_name='RNN',\n",
        "    accuracy=rnn_accuracy,\n",
        "    f1=rnn_f1,\n",
        "    precision=rnn_precision,\n",
        "    recall=rnn_recall,\n",
        "    roc_auc=rnn_roc_auc,\n",
        "    time_taken=rnn_time_taken,\n",
        "    memory_used=rnn_memory_used,\n",
        "    training_losses=rnn_training_losses,\n",
        "    validation_losses=rnn_validation_losses,\n",
        "    cm=rnn_cm\n",
        ")\n",
        "\n",
        "# For LSTM\n",
        "add_model_results(\n",
        "    model_name='LSTM',\n",
        "    accuracy=lstm_accuracy,\n",
        "    f1=lstm_f1,\n",
        "    precision=lstm_precision,\n",
        "    recall=lstm_recall,\n",
        "    roc_auc=lstm_roc_auc,\n",
        "    time_taken=lstm_time_taken,\n",
        "    memory_used=lstm_memory_used,\n",
        "    training_losses=lstm_training_losses,\n",
        "    validation_losses=lstm_validation_losses,\n",
        "    cm=lstm_cm\n",
        ")\n",
        "\n",
        "# For GRU\n",
        "add_model_results(\n",
        "    model_name='GRU',\n",
        "    accuracy=gru_accuracy,\n",
        "    f1=gru_f1,\n",
        "    precision=gru_precision,\n",
        "    recall=gru_recall,\n",
        "    roc_auc=gru_roc_auc,\n",
        "    time_taken=gru_time_taken,\n",
        "    memory_used=gru_memory_used,\n",
        "    training_losses=gru_training_losses,\n",
        "    validation_losses=gru_validation_losses,\n",
        "    cm=gru_cm\n",
        ")\n",
        "\n",
        "print(\"All model results stored successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8a95fc1-7110-4c7e-8243-5a8ad078ab36",
      "metadata": {
        "id": "e8a95fc1-7110-4c7e-8243-5a8ad078ab36"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# Recommendation System\n",
        "# ===========================\n",
        "\n",
        "def generate_recommendations(results_df):\n",
        "    # Identify the best model based on F1-Score\n",
        "    best_model_name = results_df['F1-Score'].idxmax()\n",
        "    best_model_metrics = results_df.loc[best_model_name]\n",
        "\n",
        "    print(\"\\nRecommendations:\")\n",
        "    print(f\"The best model based on F1-Score is: {best_model_name}\")\n",
        "    print(f\"Accuracy: {best_model_metrics['Accuracy']}\")\n",
        "    print(f\"F1-Score: {best_model_metrics['F1-Score']}\")\n",
        "    print(f\"Precision: {best_model_metrics['Precision']}\")\n",
        "    print(f\"Recall: {best_model_metrics['Recall']}\")\n",
        "\n",
        "    # Check if ROC-AUC is present before printing\n",
        "    if 'ROC-AUC' in best_model_metrics:\n",
        "        print(f\"ROC-AUC: {best_model_metrics['ROC-AUC']}\")\n",
        "    else:\n",
        "        print(\"ROC-AUC metric is not available for this model.\")\n",
        "\n",
        "    print(f\"Training Time (s): {best_model_metrics['Training Time (s)']}\")\n",
        "    print(f\"Memory Usage (MB): {best_model_metrics['Memory Usage (MB)']}\")\n",
        "\n",
        "    # Provide Detailed Analysis\n",
        "    print(\"\\nFinal Recommendation:\")\n",
        "    if best_model_name == 'BERT':\n",
        "        print(\"BERT provides the highest accuracy and generalization capabilities, but requires more computational resources.\")\n",
        "    elif best_model_name in ['LSTM', 'GRU']:\n",
        "        print(\"LSTM/GRU models offer a good balance between performance and computational efficiency.\")\n",
        "    elif best_model_name == 'RNN':\n",
        "        print(\"RNN is the simplest model and is best used as a baseline.\")\n",
        "    else:\n",
        "        print(f\"{best_model_name} is a custom model. Analyze its performance carefully.\")\n",
        "\n",
        "    # Generate Recommendation Report\n",
        "    recommendation_report = pd.DataFrame({\n",
        "        'Model': [best_model_name],\n",
        "        'Accuracy': [best_model_metrics['Accuracy']],\n",
        "        'F1-Score': [best_model_metrics['F1-Score']],\n",
        "        'Precision': [best_model_metrics['Precision']],\n",
        "        'Recall': [best_model_metrics['Recall']],\n",
        "        'ROC-AUC': [best_model_metrics.get('ROC-AUC', 'N/A')],  # Handle missing ROC-AUC\n",
        "        'Training Time (s)': [best_model_metrics['Training Time (s)']],\n",
        "        'Memory Usage (MB)': [best_model_metrics['Memory Usage (MB)']],\n",
        "        'Recommendation': [\"Best Model Based on Trade-offs Between Performance and Computational Efficiency\"]\n",
        "    })\n",
        "\n",
        "    print(\"\\nRecommendation System Successfully Generated.\")\n",
        "    return recommendation_report"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d00b677790242febcfa5cb77b60575c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbefbc7e606246e085571dfb73e52d6d",
              "IPY_MODEL_0d6a9ad89d9c4bb78edefefa029a408a",
              "IPY_MODEL_899993c77d1c438ca3bc0e22b3598360"
            ],
            "layout": "IPY_MODEL_787901ddb141464583c3b00fe6c910f3"
          }
        },
        "fbefbc7e606246e085571dfb73e52d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c2870f6140344f88ddb2d68ca0f0f69",
            "placeholder": "​",
            "style": "IPY_MODEL_f7eaf597631d492b8b22c1dfb15252ae",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0d6a9ad89d9c4bb78edefefa029a408a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13ce597263ee44a4a899d3a38e8a2bbe",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0bbe923adb3144afabad4432dba3ec57",
            "value": 48
          }
        },
        "899993c77d1c438ca3bc0e22b3598360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b19e483e83204dbaaa74eec31b70d375",
            "placeholder": "​",
            "style": "IPY_MODEL_1ca21310b0004aeabd5fcef9256aadfb",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.97kB/s]"
          }
        },
        "787901ddb141464583c3b00fe6c910f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c2870f6140344f88ddb2d68ca0f0f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7eaf597631d492b8b22c1dfb15252ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13ce597263ee44a4a899d3a38e8a2bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bbe923adb3144afabad4432dba3ec57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b19e483e83204dbaaa74eec31b70d375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ca21310b0004aeabd5fcef9256aadfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f71fbb0ca9374e26ae5d2310e4dffb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16a4fd9494834a5e8297be395c23f71a",
              "IPY_MODEL_c8db4d7cb53e4f96bd6e451e625284e8",
              "IPY_MODEL_10058237e8df426184e781d11e641f36"
            ],
            "layout": "IPY_MODEL_c342d85d635f4f4db3c69e03c5796210"
          }
        },
        "16a4fd9494834a5e8297be395c23f71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f163f0fe1da40969b8c51ed09600870",
            "placeholder": "​",
            "style": "IPY_MODEL_235869d2d02f456c870a570fa9f7e99a",
            "value": "vocab.txt: 100%"
          }
        },
        "c8db4d7cb53e4f96bd6e451e625284e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6d5ce885bcb4f5bad31b3bc869399a2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_152182fe82674bce98dba8bed33fa622",
            "value": 231508
          }
        },
        "10058237e8df426184e781d11e641f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc9a69b9c3e340f795083082fe7f2c4f",
            "placeholder": "​",
            "style": "IPY_MODEL_081778fcd92a4fe79abefd2502f789f9",
            "value": " 232k/232k [00:00&lt;00:00, 6.97MB/s]"
          }
        },
        "c342d85d635f4f4db3c69e03c5796210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f163f0fe1da40969b8c51ed09600870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "235869d2d02f456c870a570fa9f7e99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6d5ce885bcb4f5bad31b3bc869399a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "152182fe82674bce98dba8bed33fa622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc9a69b9c3e340f795083082fe7f2c4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "081778fcd92a4fe79abefd2502f789f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7aa929055164a33a8ab30a680864f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca3a67d2367d462d8123cdefab4209cd",
              "IPY_MODEL_a7d706469fec4b9d9b504142505a81cb",
              "IPY_MODEL_4d7debefa240474f9c62abc302bad769"
            ],
            "layout": "IPY_MODEL_44491ee6eb574239b05ab573d0e905bd"
          }
        },
        "ca3a67d2367d462d8123cdefab4209cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22e15a52ecd94eafb306c465a4021ba8",
            "placeholder": "​",
            "style": "IPY_MODEL_d30f4e92a378493f857608a076a75c5c",
            "value": "tokenizer.json: 100%"
          }
        },
        "a7d706469fec4b9d9b504142505a81cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b898e2e390a34573a95e4daa3e4a5968",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe837e1e890d45388dd70d855f54bb31",
            "value": 466062
          }
        },
        "4d7debefa240474f9c62abc302bad769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18b2340921d742f6bf35327f548d6abf",
            "placeholder": "​",
            "style": "IPY_MODEL_260ecb8e1d414067a269d1e675861269",
            "value": " 466k/466k [00:00&lt;00:00, 34.9MB/s]"
          }
        },
        "44491ee6eb574239b05ab573d0e905bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e15a52ecd94eafb306c465a4021ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d30f4e92a378493f857608a076a75c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b898e2e390a34573a95e4daa3e4a5968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe837e1e890d45388dd70d855f54bb31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18b2340921d742f6bf35327f548d6abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "260ecb8e1d414067a269d1e675861269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5bee94ee6c4419381f1cb80d2b8e7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2130536c322747da9fde1787a88de294",
              "IPY_MODEL_6fbfe8d849b242118119b58c567c3030",
              "IPY_MODEL_d34e7430bcbe4dde9067481c168dffe6"
            ],
            "layout": "IPY_MODEL_e6224bb4bcb24ee08401b1b8a8ec0940"
          }
        },
        "2130536c322747da9fde1787a88de294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad4769a8bdf47b7881da7a63e4eea90",
            "placeholder": "​",
            "style": "IPY_MODEL_4989536a16524048b032e80fa743dfd7",
            "value": "config.json: 100%"
          }
        },
        "6fbfe8d849b242118119b58c567c3030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9d23fbefb694de4b0c512cc132b1366",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb97ba8c23654957b6dfa6a62a3c8482",
            "value": 570
          }
        },
        "d34e7430bcbe4dde9067481c168dffe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa03e3f7fd9a4ea0917c40e72616de4e",
            "placeholder": "​",
            "style": "IPY_MODEL_10d45d9f21cc4d7f878cc5cc1ae96f2b",
            "value": " 570/570 [00:00&lt;00:00, 64.4kB/s]"
          }
        },
        "e6224bb4bcb24ee08401b1b8a8ec0940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad4769a8bdf47b7881da7a63e4eea90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4989536a16524048b032e80fa743dfd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9d23fbefb694de4b0c512cc132b1366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb97ba8c23654957b6dfa6a62a3c8482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa03e3f7fd9a4ea0917c40e72616de4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d45d9f21cc4d7f878cc5cc1ae96f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}